{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "# from scipy.stats import pmean, hmean, gmean\n",
    "from scipy import stats\n",
    "from skimage.io import imread, imsave\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16994e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdir='/workspace/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f00599",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fetal_img_path ='/fetal/all/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "feat_mat=[]\n",
    "for imgfile in os.listdir(imgdir+all_fetal_img_path):\n",
    "    img = imread(imgdir+all_fetal_img_path+'/'+imgfile)\n",
    "#     l = list(stats.describe(img[...,2].ravel()/255.0))[1:]\n",
    "    l = list(stats.describe(img[...,2].ravel()/255.0))[1:]\n",
    "    img_feature=list(l[0])+l[1:]\n",
    "    feat_mat.append(img_feature)\n",
    "#     print(stats.pmean(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b32847",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_mat=np.array(feat_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cfb811",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf870e2d",
   "metadata": {},
   "source": [
    "# Running clustering Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "kmeans.fit(feat_mat)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c6f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(kmeans.labels_,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48534f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_images(cluster_number,images_to_show,ret_list=False,img_show=True):\n",
    "    i=0\n",
    "    clust_n = np.where(np.array(kmeans.labels_) == cluster_number)\n",
    "    clust_n_imglist=np.array(os.listdir(imgdir+all_fetal_img_path))[clust_n]\n",
    "    if ret_list:\n",
    "        return clust_n_imglist\n",
    "    for imgfile in clust_n_imglist:\n",
    "        img = imread(imgdir+all_fetal_img_path+'/'+imgfile)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        i+=1\n",
    "        if i == images_to_show:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583777ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.unique(kmeans.labels_,return_counts=True)[0]:\n",
    "    print('clust_number ' , i)\n",
    "    visualise_images(i,5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62291aaf",
   "metadata": {},
   "source": [
    "# Running Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e69b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from mrcnn.config import Config\n",
    "import numpy as np\n",
    "from mrcnn import model as modellib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NucleusConfig(Config):\n",
    "    \"\"\"Configuration for training on the nissl segmentation dataset. while using command \"train\"\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"nissl\"\n",
    "\n",
    "    # Adjust depending on your GPU memory\n",
    "    IMAGES_PER_GPU = 1\n",
    "    GPU_COUNT = 1 # since multiprocessing doesn't work\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + cell\n",
    "\n",
    "    # Number of training and validation steps per epoch\n",
    "    # 238 is the size of train set\n",
    "    STEPS_PER_EPOCH = 218 // (IMAGES_PER_GPU * GPU_COUNT)\n",
    "    VALIDATION_STEPS = max(1, 20 // (IMAGES_PER_GPU * GPU_COUNT))\n",
    "\n",
    "    # Don't exclude based on confidence. Since we have two classes\n",
    "    # then 0.5 is the minimum anyway as it picks between nissl and BG\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7\n",
    "\n",
    "    # Backbone network architecture\n",
    "    # Supported values are: resnet50, resnet101\n",
    "    BACKBONE = \"resnet50\"\n",
    "\n",
    "    # Input image resizing\n",
    "    # Random crops of size 512x512\n",
    "    IMAGE_RESIZE_MODE = \"crop\"\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "\n",
    "    # Length of square anchor side in pixels\n",
    "    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)\n",
    "\n",
    "    # Ratios of anchors at each cell (width/height)\n",
    "    # A value of 1 represents a square anchor, and 0.5 is a wide anchor\n",
    "    RPN_ANCHOR_RATIOS = [0.5, 1, 2, 4]\n",
    "\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.9\n",
    "\n",
    "    # ROIs kept after non-maximum supression (training and inference)\n",
    "    POST_NMS_ROIS_TRAINING = 1000\n",
    "    POST_NMS_ROIS_INFERENCE = 2000\n",
    "\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.9\n",
    "\n",
    "    # How many anchors per image to use for RPN training\n",
    "    # RPN_TRAIN_ANCHORS_PER_IMAGE = 64\n",
    "\n",
    "    # Image mean (RGB)\n",
    "    # setting means for R and G to 0 since cells are mostly blue\n",
    "    MEAN_PIXEL = np.array([0, 0, 103.9])\n",
    "\n",
    "    # If enabled, resizes instance masks to a smaller size to reduce\n",
    "    # memory load. Recommended when using high-resolution images.\n",
    "    USE_MINI_MASK = True\n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "    IMAGE_CHANNEL_COUNT = 3\n",
    "\n",
    "    # Number of ROIs per image to feed to classifier/mask heads\n",
    "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
    "    # enough positive proposals to fill this and keep a positive:negative\n",
    "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
    "    # the RPN NMS threshold.\n",
    "    TRAIN_ROIS_PER_IMAGE = 128\n",
    "\n",
    "    # Maximum number of ground truth instances to use in one image\n",
    "    MAX_GT_INSTANCES = 400\n",
    "\n",
    "    # Max number of final detections per image\n",
    "    DETECTION_MAX_INSTANCES = 800\n",
    "# In[5]:\n",
    "class NucleusInferenceConfig(NucleusConfig):\n",
    "    \"\"\"Test-time configurations. while using command \"test\" or \"detect\"\n",
    "    \"\"\"\n",
    "    # Set batch size to 1 to run one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    IMAGE_RESIZE_MODE = \"crop\"\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.9\n",
    "    USE_MINI_MASK = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d121a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_out_array(out):\n",
    "    out_combined = out[...,0].astype(np.uint16)\n",
    "    for x in range(1,out.shape[-1]):\n",
    "        out_combined += out[...,x].astype(np.uint16)*(x+1) \n",
    "    return out_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = NucleusInferenceConfig()\n",
    "model = modellib.MaskRCNN(mode='inference', config=config, model_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67723cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('mask_rcnn_nucleus_NISSL.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fetal_annot_path='/fetal/all/annotated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ae6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.unique(kmeans.labels_,return_counts=True)[0]:\n",
    "    print('clust_number ' , i)\n",
    "    imgfile_list = visualise_images(i,5,True,False)\n",
    "\n",
    "    for imgfile in imgfile_list:\n",
    "        img_crop = imread(imgdir + all_fetal_img_path+'/'+imgfile)\n",
    "        r = model.detect([img_crop],verbose=1)\n",
    "        out = r[0]['masks']\n",
    "        combined_out = combine_out_array(out)\n",
    "        annot = imread(imgdir+all_fetal_annot_path+'/' + imgfile.split('.')[0].split('_')[-1]+'.png')\n",
    "\n",
    "        plt.figure(figsize=(16,16))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(img_crop)\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow((combined_out>0).astype(np.uint8) + 2*(annot[...,0]>0).astype(np.uint8) , cmap='hot')\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4452bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgfile.split('.')[0].split('_')[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
